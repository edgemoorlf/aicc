#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•DashScope ASRåŠŸèƒ½çš„ä¸“ç”¨è„šæœ¬
ä½¿ç”¨ tests/test-fixed-greeting.wav ä½œä¸ºæµ‹è¯•éŸ³é¢‘
"""

import os
import sys
import dashscope
from dashscope.audio.asr import Recognition
from dotenv import load_dotenv

# åŠ è½½.envæ–‡ä»¶
load_dotenv()

def test_dashscope_asr():
    """æµ‹è¯•DashScope ASR API"""
    print("ğŸ™ï¸ æµ‹è¯•DashScope ASRåŠŸèƒ½...")
    print("="*50)
    
    # æ£€æŸ¥API Key
    api_key = os.getenv('DASHSCOPE_API_KEY')
    if not api_key:
        print("âŒ é”™è¯¯: è¯·è®¾ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡")
        return False
        
    dashscope.api_key = api_key
    print(f"âœ… API Keyå·²è®¾ç½®: {api_key[:10]}...")
    
    # æ£€æŸ¥æµ‹è¯•éŸ³é¢‘æ–‡ä»¶
    test_audio_path = "/var/folders/yb/0_c4yn7n0ws6cvl85tfcwjrw0000gn/T/tmph2x6tczz.webm"
    if not os.path.exists(test_audio_path):
        print(f"âŒ é”™è¯¯: WebMæµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_audio_path}")
        # å›é€€åˆ°16ä½æµ‹è¯•æ–‡ä»¶
        test_audio_path = "/tmp/test_16bit.wav"
        if not os.path.exists(test_audio_path):
            print(f"âŒ é”™è¯¯: 16ä½æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_audio_path}")
            # å›é€€åˆ°åŸç”Ÿæˆçš„æ–‡ä»¶
            test_audio_path = "/var/folders/yb/0_c4yn7n0ws6cvl85tfcwjrw0000gn/T/tmpda0llkmi.wav"
            if not os.path.exists(test_audio_path):
                print(f"âŒ é”™è¯¯: åŸç”Ÿæˆæ–‡ä»¶ä¹Ÿä¸å­˜åœ¨: {test_audio_path}")
                # æœ€åå›é€€åˆ°åŸå§‹æµ‹è¯•æ–‡ä»¶
                test_audio_path = "../tests/test-fixed-greeting.wav"
                if not os.path.exists(test_audio_path):
                    print(f"âŒ é”™è¯¯: æ‰€æœ‰æµ‹è¯•æ–‡ä»¶éƒ½ä¸å­˜åœ¨")
                    return False
                else:
                    print(f"ğŸ“ ä½¿ç”¨åŸå§‹æµ‹è¯•æ–‡ä»¶: {test_audio_path}")
            else:
                print(f"ğŸ“ ä½¿ç”¨32ä½ç”Ÿæˆæ–‡ä»¶: {test_audio_path}")
        else:
            print(f"ğŸ“ ä½¿ç”¨16ä½è½¬æ¢æ–‡ä»¶: {test_audio_path}")
    else:
        print(f"ğŸ“ ä½¿ç”¨WebMæµ‹è¯•æ–‡ä»¶: {test_audio_path}")
    
    try:
        # åˆ›å»ºRecognitionå®ä¾‹
        print("\nğŸ”§ åˆ›å»ºRecognitionå®ä¾‹...")
        
        # å°è¯•ä¸åŒçš„æ¨¡å‹å‚æ•°
        models_to_try = [
            {
                'model': 'paraformer-realtime-8k-v2',
                'format': 'webm',
                'sample_rate': 8000,  # 8kHzæ¨¡å‹
                'callback': None
            },
            {
                'model': 'paraformer-realtime-8k-v2',
                'format': 'wav',
                'sample_rate': 8000,  # 8kHzæ¨¡å‹
                'callback': None
            },
            {
                'model': 'paraformer-realtime-v2',
                'format': 'webm',
                'sample_rate': 48000,  # WebMæ–‡ä»¶çš„å®é™…é‡‡æ ·ç‡
                'callback': None
            },
            {
                'model': 'paraformer-realtime-v2',
                'format': 'webm',
                'sample_rate': 16000,  # å°è¯•16kHz
                'callback': None
            },
            {
                'model': 'paraformer-realtime-v2',
                'format': 'wav',
                'sample_rate': 16000,
                'callback': None
            }
        ]
        
        # å¦‚æœä½¿ç”¨WAVæ ¼å¼ï¼Œå…ˆè½¬æ¢WebMåˆ°WAV
        for i, model_config in enumerate(models_to_try):
            print(f"\nğŸ”§ å°è¯•æ¨¡å‹é…ç½® {i+1}: {model_config['model']} ({model_config['format']}@{model_config['sample_rate']}Hz)")
            
            # ç¡®å®šè¦ä½¿ç”¨çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            audio_file_path = test_audio_path
            
            # å¦‚æœæ¨¡å‹è¦æ±‚WAVæ ¼å¼ä½†æˆ‘ä»¬æœ‰WebMæ–‡ä»¶ï¼Œè¿›è¡Œè½¬æ¢
            if model_config['format'] == 'wav' and test_audio_path.endswith('.webm'):
                try:
                    from pydub import AudioSegment
                    import tempfile
                    
                    print(f"ğŸ“ è½¬æ¢WebMåˆ°WAVæ ¼å¼ ({model_config['sample_rate']}Hz)...")
                    
                    # è¯»å–WebMæ–‡ä»¶
                    audio = AudioSegment.from_file(test_audio_path, format="webm")
                    
                    # è½¬æ¢ä¸ºæŒ‡å®šé‡‡æ ·ç‡å’Œæ ¼å¼
                    audio = audio.set_frame_rate(model_config['sample_rate']).set_channels(1).set_sample_width(2)
                    
                    # ä¿å­˜ä¸ºä¸´æ—¶WAVæ–‡ä»¶
                    wav_file_path = test_audio_path.replace('.webm', f'_{model_config["sample_rate"]}hz.wav')
                    audio.export(wav_file_path, format="wav")
                    
                    audio_file_path = wav_file_path
                    print(f"âœ… WAVè½¬æ¢å®Œæˆ: {wav_file_path}")
                    
                except Exception as convert_error:
                    print(f"âŒ WAVè½¬æ¢å¤±è´¥: {convert_error}")
                    continue
            
            try:
                recognition = Recognition(**model_config)
                print(f"âœ… Recognitionå®ä¾‹åˆ›å»ºæˆåŠŸ: {model_config['model']}")
                
                # è¿›è¡Œè¯­éŸ³è¯†åˆ«
                print(f"\nğŸ¯ å¼€å§‹è¯­éŸ³è¯†åˆ« (æ–‡ä»¶: {audio_file_path})...")
                result = recognition.call(audio_file_path)
                
                print(f"ğŸ“Š ASRç»“æœç±»å‹: {type(result)}")
                print(f"ğŸ“Š ASRç»“æœå†…å®¹: {result}")
                
                # æ£€æŸ¥ç»“æœ
                if hasattr(result, 'output') and result.output is not None:
                    print(f"ğŸ‰ æ¨¡å‹ {model_config['model']} æˆåŠŸè¿”å›ç»“æœ!")
                    
                    # å°è¯•å¤šç§æ–¹å¼æå–ç»“æœ  
                    transcript = None
                    
                    if hasattr(result, 'get_sentence'):
                        try:
                            transcript = result.get_sentence()
                            print(f"âœ… é€šè¿‡get_sentence()è·å–ç»“æœ: {transcript}")
                            break
                        except Exception as e:
                            print(f"âš ï¸  get_sentence()è°ƒç”¨å¤±è´¥: {e}")
                    
                    if not transcript and hasattr(result, 'output'):
                        print(f"ğŸ“Š Outputç±»å‹: {type(result.output)}")
                        print(f"ğŸ“Š Outputå†…å®¹: {result.output}")
                        
                        if hasattr(result.output, 'sentence'):
                            transcript = result.output.sentence
                            print(f"âœ… é€šè¿‡output.sentenceè·å–ç»“æœ: {transcript}")
                        elif isinstance(result.output, dict):
                            transcript = result.output.get('sentence', '') or result.output.get('text', '')
                            print(f"âœ… é€šè¿‡å­—å…¸é”®è·å–ç»“æœ: {transcript}")
                    
                    if transcript:
                        print(f"\nğŸ‰ è¯†åˆ«æˆåŠŸ!")
                        print(f"ğŸ“ è½¬å½•ç»“æœ: \"{transcript}\"")
                        return True
                else:
                    print(f"âŒ æ¨¡å‹ {model_config['model']} è¿”å›ç©ºç»“æœ")
                    
            except Exception as e:
                print(f"âŒ æ¨¡å‹ {model_config['model']} æµ‹è¯•å¤±è´¥: {str(e)}")
                continue
        
        print("âŒ æ‰€æœ‰æ¨¡å‹éƒ½æ— æ³•æˆåŠŸè¯†åˆ«")
        return False
            
    except Exception as e:
        print(f"âŒ ASRæµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("ğŸš€ DashScope ASRç‹¬ç«‹æµ‹è¯•")
    print("æµ‹è¯•éŸ³é¢‘æ–‡ä»¶: tests/test-fixed-greeting.wav")
    print()
    
    success = test_dashscope_asr()
    
    if success:
        print("\n" + "="*50)
        print("âœ… ASRæµ‹è¯•é€šè¿‡! DashScopeè¯­éŸ³è¯†åˆ«åŠŸèƒ½æ­£å¸¸")
    else:
        print("\n" + "="*50)
        print("âŒ ASRæµ‹è¯•å¤±è´¥")
    
    sys.exit(0 if success else 1)