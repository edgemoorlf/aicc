#!/usr/bin/env python3
"""
Aliyun CCC Consolidated Server - POC Implementation
Consolidates qwen/firefox client+server logic for telephony inbound calls

Key Features:
- Handles inbound CCC calls with auto-greeting
- G.711 â†” PCM audio conversion for 8kHz telephony
- Persistent DashScope connections (ASR/LLM/TTS)
- In-memory session state (no concurrency)
- Professional debt collection conversation flow

Architecture:
Customer Calls â†’ CCC Inbound â†’ Function Compute â†’ Consolidated Server â†’ DashScope
"""

import os
import json
import time
import logging
import base64
import tempfile
import audioop
import asyncio
from typing import Dict, Optional, Any
from pathlib import Path

# Load environment variables from .env file
from dotenv import load_dotenv
load_dotenv()

# Aliyun CCC SDK
from alibabacloud_ccc20200701.client import Client as CccClient
from alibabacloud_ccc20200701 import models as ccc_models
from alibabacloud_tea_openapi import models as open_api_models

# DashScope imports
import dashscope
from dashscope.audio.asr import Recognition, RecognitionCallback, RecognitionResult
from dashscope import Generation
import dashscope.audio.qwen_tts

# Configuration
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ccc_consolidated_server.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Environment variables (loaded from .env file)
DASHSCOPE_API_KEY = os.getenv('DASHSCOPE_API_KEY')
ALIYUN_ACCESS_KEY_ID = os.getenv('ALIYUN_ACCESS_KEY_ID')
ALIYUN_ACCESS_KEY_SECRET = os.getenv('ALIYUN_ACCESS_KEY_SECRET')
ALIYUN_CCC_INSTANCE_ID = os.getenv('ALIYUN_CCC_INSTANCE_ID')
ALIYUN_REGION = os.getenv('ALIYUN_REGION', 'cn-shanghai')

# Validate configuration
if not DASHSCOPE_API_KEY:
    logger.error('âŒ DASHSCOPE_API_KEY not found in environment variables')
    raise ValueError('Please set DASHSCOPE_API_KEY in .env file')

if not ALIYUN_ACCESS_KEY_ID or not ALIYUN_ACCESS_KEY_SECRET:
    logger.error('âŒ Aliyun access keys not found in environment variables')
    raise ValueError('Please set ALIYUN_ACCESS_KEY_ID and ALIYUN_ACCESS_KEY_SECRET in .env file')

# Configure DashScope API
dashscope.api_key = DASHSCOPE_API_KEY
logger.info("âœ… DashScope API configured for CCC telephony integration")
logger.info(f"âœ… Environment loaded: DashScope key configured, Aliyun region: {ALIYUN_REGION}")

# Global persistent connections and state
asr_session = None
llm_client = None
tts_client = None
conversation_sessions = {}  # In-memory session storage (no concurrency)

# Voice settings for professional collection agent
voice_settings = {
    'speed': 1.0,
    'pitch': 1.0, 
    'volume': 0.8,
    'voice': 'Cherry',
    'tone': 'professional',
    'emotion': 'professional'
}

class TelephonyASRProcessor:
    """Telephony ASR Processor - Adapted from FirefoxStreamingASRSession"""
    
    def __init__(self, call_id: str):
        self.call_id = call_id
        self.recognition = None
        self.is_active = False
        self.start_time = None
        
        # Sentence completion detection
        self.last_partial_text = ""
        self.last_update_time = 0
        self.sentence_timeout = 2000  # 2s timeout for sentence completion
        self.pending_final_check = None
        
        # Connection management
        self.consecutive_failures = 0
        self.max_consecutive_failures = 3
        self.last_restart_time = 0
        self.restart_cooldown = 5.0
        
        # ASR latency measurement
        self.sentence_end_time = None
        self.last_audio_time = None
        
    def start_telephony_asr(self):
        """Start telephony ASR with 8kHz PCM support"""
        try:
            logger.info(f'ğŸ“ Starting telephony ASR session: {self.call_id}')
            
            # Create callback instance
            callback = TelephonyASRCallback(self)
            
            # Create Recognition instance for telephony (8kHz PCM)
            self.recognition = Recognition(
                model="paraformer-realtime-v2",  # Supports any sampling rate
                format="wav",  # PCM WAV format from G.711 conversion
                sample_rate=8000,  # CCC telephony standard 8kHz
                callback=callback,
                # Telephony optimization parameters
                semantic_punctuation_enabled=True,
                max_sentence_silence=1500,  # 1.5s for phone conversations
                heartbeat=True,
                multi_threshold_mode_enabled=True
            )
            
            # Start recognition
            self.recognition.start()
            self.is_active = True
            self.start_time = time.time()
            
            logger.info(f'âœ… Telephony ASR started: {self.call_id} (8kHz PCM)')
            return True
            
        except Exception as e:
            logger.error(f'âŒ Telephony ASR startup failed: {e}')
            self.is_active = False
            self.recognition = None
            return False
    
    def send_audio_data(self, g711_audio_data: bytes) -> bool:
        """Send G.711 audio data to ASR (convert to PCM first)"""
        try:
            # Convert G.711 to PCM WAV (8kHz)
            pcm_data = g711_to_wav_8khz(g711_audio_data)
            
            if not self.recognition or not self.is_active:
                if not self.restart_telephony_asr():
                    return False
                    
            # Record audio receive time for latency calculation
            self.last_audio_time = time.time()
            
            # Send PCM data to DashScope ASR
            self.recognition.send_audio_frame(pcm_data)
            
            logger.debug(f'ğŸ“¤ Telephony audio processed: {len(g711_audio_data)} G.711 â†’ {len(pcm_data)} PCM')
            return True
            
        except Exception as e:
            logger.error(f'âŒ Telephony audio processing failed: {e}')
            self.consecutive_failures += 1
            self.last_restart_time = time.time()
            
            if self.recognition:
                try:
                    self.recognition.stop()
                except:
                    pass
                self.recognition = None
                self.is_active = False
            return False
    
    def restart_telephony_asr(self):
        """Restart telephony ASR with backoff"""
        try:
            current_time = time.time()
            if current_time - self.last_restart_time < self.restart_cooldown:
                logger.warning(f'ASR restart cooldown: {self.restart_cooldown - (current_time - self.last_restart_time):.1f}s remaining')
                return False
                
            if self.consecutive_failures >= self.max_consecutive_failures:
                logger.error(f'Max ASR failures reached: {self.max_consecutive_failures}')
                return False
            
            # Clean up existing connection
            if self.recognition:
                try:
                    self.recognition.stop()
                except:
                    pass
                self.recognition = None
                self.is_active = False
            
            time.sleep(2.0)  # Allow DashScope cleanup
            logger.info(f'ğŸ”„ Restarting telephony ASR: {self.call_id}')
            
            return self.start_telephony_asr()
            
        except Exception as e:
            logger.error(f'âŒ Telephony ASR restart failed: {e}')
            return False
    
    def stop_telephony_asr(self):
        """Stop telephony ASR"""
        try:
            if self.recognition and self.is_active:
                self.recognition.stop()
                self.is_active = False
                logger.info(f'ğŸ›‘ Telephony ASR stopped: {self.call_id}')
        except Exception as e:
            logger.error(f'âŒ Stop ASR failed: {e}')

class TelephonyASRCallback(RecognitionCallback):
    """Telephony ASR Callback - Adapted from FirefoxASRCallback"""
    
    def __init__(self, asr_processor):
        self.asr_processor = asr_processor
        self.recognition_start_time = None
        
    def on_open(self):
        self.recognition_start_time = time.time()
        logger.info(f"âœ… Telephony ASR connection established: {self.asr_processor.call_id}")
        
    def on_event(self, result):
        if isinstance(result, RecognitionResult):
            sentence = result.get_sentence()
            
            if sentence:
                text = sentence.get('text', '')
                confidence = sentence.get('confidence', 0.8)  # Default confidence
                is_sentence_end = sentence.get('sentence_end', False) or sentence.get('is_final', False)
                
                # Calculate ASR latency
                current_time = time.time()
                asr_latency = 200  # Default latency
                if is_sentence_end and self.asr_processor.last_audio_time:
                    asr_latency = (current_time - self.asr_processor.last_audio_time) * 1000
                    asr_latency = max(50, min(asr_latency, 3000))  # 50ms-3s range
                
                logger.info(f"ğŸ“ Telephony ASR result: '{text}' (confidence: {confidence:.2f}, latency: {asr_latency:.1f}ms, final: {is_sentence_end})")
                
                # Process complete sentences for LLM
                if text.strip() and confidence > 0.3 and is_sentence_end:
                    logger.info(f'ğŸ¯ Complete sentence recognized: {text}')
                    # Trigger LLM processing through conversation handler
                    handle_customer_speech(self.asr_processor.call_id, text)
                    
    def on_error(self, error):
        logger.error(f"âŒ Telephony ASR error: {error}")
        
    def on_close(self):
        logger.info(f"ğŸ”’ Telephony ASR connection closed: {self.asr_processor.call_id}")

def g711_to_wav_8khz(g711_data: bytes) -> bytes:
    """Convert G.711 (A-law/Î¼-law) to 8kHz PCM WAV for DashScope ASR"""
    try:
        # Detect G.711 format (A-law vs Î¼-law)
        # For CCC, typically A-law for international, Î¼-law for North America
        # We'll try A-law first, then Î¼-law as fallback
        
        try:
            # Try A-law decoding first (international standard)
            pcm_16bit = audioop.alaw2lin(g711_data, 2)  # 2 bytes = 16-bit samples
            conversion_type = "A-law"
        except audioop.error:
            try:
                # Fallback to Î¼-law decoding (North America standard)
                pcm_16bit = audioop.ulaw2lin(g711_data, 2)  # 2 bytes = 16-bit samples
                conversion_type = "Î¼-law"
            except audioop.error:
                logger.error('âŒ G.711 data is neither valid A-law nor Î¼-law')
                return b''
        
        # Create WAV header for 8kHz, 16-bit, mono PCM
        wav_header = create_wav_header(len(pcm_16bit), sample_rate=8000, channels=1, bits_per_sample=16)
        wav_data = wav_header + pcm_16bit
        
        logger.debug(f'ğŸ”„ G.711 conversion: {len(g711_data)} bytes {conversion_type} â†’ {len(pcm_16bit)} bytes PCM â†’ {len(wav_data)} bytes WAV (8kHz, 16-bit, mono)')
        return wav_data
        
    except Exception as e:
        logger.error(f'âŒ G.711 to WAV conversion failed: {e}')
        return b''

def pcm_24khz_to_g711_8khz(pcm_data: bytes) -> bytes:
    """Downsample 24kHz PCM to 8kHz G.711 for CCC telephony output"""
    try:
        # Step 1: Resample 24kHz â†’ 8kHz (3:1 ratio)
        # audioop.ratecv(fragment, width, nchannels, inrate, outrate, state, weightA, weightB)
        downsampled_pcm, _ = audioop.ratecv(
            pcm_data,      # Input PCM data
            2,             # Sample width (16-bit = 2 bytes)
            1,             # Mono (1 channel)
            24000,         # Input sample rate
            8000,          # Output sample rate (CCC telephony standard)
            None           # State (None for first call)
        )
        
        # Step 2: Convert 16-bit PCM to G.711 A-law (international standard)
        g711_alaw = audioop.lin2alaw(downsampled_pcm, 2)  # 2 = 16-bit input
        
        logger.debug(f'ğŸ”„ PCM to G.711 conversion: {len(pcm_data)} bytes 24kHz PCM â†’ {len(downsampled_pcm)} bytes 8kHz PCM â†’ {len(g711_alaw)} bytes A-law')
        return g711_alaw
        
    except Exception as e:
        logger.error(f'âŒ PCM to G.711 conversion failed: {e}')
        return b''

def create_wav_header(data_length: int, sample_rate: int = 8000, channels: int = 1, bits_per_sample: int = 16) -> bytes:
    """Create WAV file header for PCM data"""
    byte_rate = sample_rate * channels * bits_per_sample // 8
    block_align = channels * bits_per_sample // 8
    
    header = b'RIFF'                                    # Chunk ID
    header += (36 + data_length).to_bytes(4, 'little') # Chunk size
    header += b'WAVE'                                   # Format
    header += b'fmt '                                   # Subchunk1 ID
    header += (16).to_bytes(4, 'little')               # Subchunk1 size
    header += (1).to_bytes(2, 'little')                # Audio format (PCM)
    header += channels.to_bytes(2, 'little')           # Channels
    header += sample_rate.to_bytes(4, 'little')        # Sample rate
    header += byte_rate.to_bytes(4, 'little')          # Byte rate
    header += block_align.to_bytes(2, 'little')        # Block align
    header += bits_per_sample.to_bytes(2, 'little')    # Bits per sample
    header += b'data'                                   # Subchunk2 ID
    header += data_length.to_bytes(4, 'little')        # Subchunk2 size
    
    return header

def initialize_persistent_connections():
    """Initialize and maintain persistent DashScope connections"""
    global asr_session, llm_client, tts_client
    
    try:
        logger.info('ğŸ”¥ Initializing persistent DashScope connections...')
        
        # Pre-configure LLM client
        llm_client = Generation
        logger.info('âœ… LLM client ready')
        
        # Pre-configure TTS client  
        tts_client = dashscope.audio.qwen_tts.SpeechSynthesizer
        logger.info('âœ… TTS client ready')
        
        logger.info('ğŸš€ All persistent connections initialized')
        return True
        
    except Exception as e:
        logger.error(f'âŒ Persistent connection initialization failed: {e}')
        return False

def build_collection_prompt(customer_context: Dict, conversation_history: list) -> str:
    """Build professional collection agent prompt - Telephony version"""
    
    def format_chinese_amount(amount: int) -> str:
        """Format amount in Chinese: 15000 â†’ ä¸€ä¸‡äº”åƒå…ƒ"""
        if amount >= 10000:
            wan = amount // 10000
            remainder = amount % 10000
            if remainder == 0:
                return f"{wan}ä¸‡å…ƒ"
            else:
                return f"{wan}ä¸‡{remainder}å…ƒ"
        return f"{amount}å…ƒ"
    
    # Build conversation history
    conversation_text = ""
    if conversation_history:
        conversation_text = "\næœ¬æ¬¡é€šè¯è®°å½•:\n"
        for i, entry in enumerate(conversation_history):
            role = "å®¢æˆ·" if entry.get('sender') == 'customer' else "å‚¬æ”¶å‘˜"
            conversation_text += f"{i+1}. {role}: {entry.get('text', '')}\n"
    else:
        conversation_text = "\næœ¬æ¬¡é€šè¯è®°å½•:\n(å¼€å§‹æ–°å¯¹è¯)\n"
    
    system_prompt = f"""ä½ æ˜¯å¹³å®‰é“¶è¡Œä¿¡ç”¨å¡ä¸­å¿ƒçš„ä¸“ä¸šå‚¬æ”¶ä¸“å‘˜ï¼Œæ­£åœ¨è¿›è¡Œç”µè¯å‚¬æ”¶å·¥ä½œã€‚

å®¢æˆ·æ¡£æ¡ˆä¿¡æ¯:
- å®¢æˆ·å§“å: {customer_context.get('name', 'å®¢æˆ·')}
- é€¾æœŸæœ¬é‡‘: {format_chinese_amount(customer_context.get('balance', 15000))}
- é€¾æœŸå¤©æ•°: {customer_context.get('daysOverdue', 30)}å¤©
- è”ç³»å†å²: {customer_context.get('previousContacts', 2)}æ¬¡
- é£é™©ç­‰çº§: {customer_context.get('riskLevel', 'ä¸­ç­‰')}

{conversation_text}

åŸºäºçœŸå®å‚¬æ”¶å¯¹è¯çš„æ ‡å‡†è¯æœ¯:

ã€æ ¸å®ç¡®è®¤ã€‘
- "æˆ‘çœ‹æ‚¨è¿™è¾¹çš„è¯åœ¨[æ—¥æœŸ]è¿˜äº†ä¸€ç¬”ï¼Œè¿˜äº†[é‡‘é¢]"
- "å½“å‰çš„è¯è¿˜å·®[å…·ä½“é‡‘é¢]ï¼Œæ²¡æœ‰è¿˜å¤Ÿ"

ã€ç†è§£å›åº”ã€‘  
- "ä¹Ÿæ²¡æœ‰äººè¯´æœ‰é’±ä¸å»è¿˜è¿™ä¸ªä¿¡ç”¨å¡çš„ï¼Œæˆ‘å¯ä»¥ç†è§£"
- "å¯ä»¥ç†è§£ï¼Œæ‚¨çš„è¿˜æ¬¾å‹åŠ›ç¡®å®ä¹Ÿæ˜¯æŒºå¤§çš„"

ã€æ–¹æ¡ˆæä¾›ã€‘
- "å½“å‰çš„è¯è¿˜æ˜¯å±äºä¸€ä¸ªå†…éƒ¨åå•†"
- "é“¶è¡Œè¿™è¾¹å¯ä»¥å¸®æ‚¨å‡å…ä¸€éƒ¨åˆ†æ¯è´¹"
- "è¿˜å¯ä»¥å¸®æ‚¨å»æ’¤é”€è¿™ä¸ªä½™è–ªæ¡ˆä»¶çš„"

ã€ä¸“ä¸šç”¨è¯­ã€‘
- ä½¿ç”¨"æ‚¨è¿™è¾¹çš„è¯"ã€"å½“å‰çš„è¯"ã€"æ˜¯å§"ç­‰çœŸå®å‚¬æ”¶ç”¨è¯­
- ä½¿ç”¨"å†…éƒ¨åå•†"ã€"ä½™è–ªæ¡ˆä»¶"ã€"å…¨é¢å‡å…æ–¹æ¡ˆæ”¿ç­–"ç­‰ä¸“ä¸šæœ¯è¯­

ã€é‡è¦åŸåˆ™ã€‘
1. ä¿æŒç†è§£è€å¿ƒçš„æ€åº¦ï¼Œé¿å…å¼ºç¡¬æ–½å‹
2. ç”¨å…·ä½“æ•°æ®å»ºç«‹å¯ä¿¡åº¦  
3. æä¾›å¤šç§è§£å†³æ–¹æ¡ˆ
4. å…³æ³¨å®¢æˆ·æ„Ÿå—å’Œå®é™…å›°éš¾
5. ä½¿ç”¨é“¶è¡Œä¸“ä¸šæœ¯è¯­å¢å¼ºæƒå¨æ€§
6. æ¯ä¸€æ¬¡å›ç­”å°½é‡ç®€ç»ƒï¼Œä¸è¦è¶…è¿‡4å¥è¯ï¼Œæœ€å¥½åœ¨1-2å¥ï¼Œé¿å…é•¿ç¯‡å¤§è®ºï¼Œç¡®ä¿å®¢æˆ·èƒ½å¬æ‡‚
7. **ä¸¥ç¦é‡å¤ä¹‹å‰å·²ç»è¯´è¿‡çš„å†…å®¹** - ä»”ç»†æŸ¥çœ‹é€šè¯è®°å½•ï¼Œé¿å…é‡å¤ç›¸åŒçš„è¯æœ¯ã€é—®é¢˜æˆ–ä¿¡æ¯
8. **æ ¹æ®å¯¹è¯è¿›å±•è°ƒæ•´ç­–ç•¥** - æ¯æ¬¡å›å¤éƒ½è¦åŸºäºå®¢æˆ·çš„æœ€æ–°å›åº”ï¼Œæ¨è¿›å¯¹è¯è€Œä¸æ˜¯é‡å¤

è¯­è¨€è¦æ±‚:
- ä½¿ç”¨å¤§é™†æ ‡å‡†æ™®é€šè¯ï¼Œé¿å…å°æ¹¾ç”¨è¯­
- é‡‘é¢è¡¨è¾¾: 15000å…ƒè¯´æˆ"ä¸€ä¸‡äº”åƒå…ƒ"ï¼Œä¸æ˜¯"åäº”åƒå…ƒ"
- è¯­æ°”è¦ä¸“ä¸šã€ç†è§£ï¼Œä½“ç°äººæ–‡å…³æ€€

è¯·ä»¥ä¸“ä¸šå‚¬æ”¶å‘˜çš„èº«ä»½ï¼Œé’ˆå¯¹å®¢æˆ·çš„è¯è¯­ç»™å‡ºåˆé€‚çš„å›åº”ï¼Œæ¨è¿›å‚¬æ”¶å¯¹è¯ã€‚"""

    return system_prompt

def process_telephony_llm_and_tts(call_id: str, user_text: str):
    """Process customer speech through LLM and generate TTS response"""
    try:
        logger.info(f'ğŸ’¬ Processing customer speech: "{user_text}" (call: {call_id})')
        llm_start = time.time()
        
        # Get session context
        session = conversation_sessions.get(call_id, {})
        customer_context = session.get('customer_context', {
            'name': 'å®¢æˆ·',
            'balance': 15000,
            'daysOverdue': 30,
            'previousContacts': 2,
            'riskLevel': 'ä¸­ç­‰'
        })
        
        conversation_history = session.get('history', [])
        
        # Build collection prompt
        system_prompt = build_collection_prompt(customer_context, conversation_history)
        
        logger.info('ğŸ§  Calling Qwen LLM...')
        response = llm_client.call(
            model='qwen-turbo-latest',
            messages=[
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': user_text}
            ],
            temperature=0.7,
            max_tokens=500,
            result_format='message'
        )
        
        llm_latency = (time.time() - llm_start) * 1000
        
        if response.status_code == 200:
            ai_response = response.output.choices[0].message.content
            logger.info(f"ğŸ’¬ LLM response: '{ai_response}' (latency: {llm_latency:.1f}ms)")
            
            # Update conversation history
            session['history'].extend([
                {'sender': 'customer', 'text': user_text, 'timestamp': time.time()},
                {'sender': 'agent', 'text': ai_response, 'timestamp': time.time()}
            ])
            conversation_sessions[call_id] = session
            
            # Generate TTS audio
            generate_telephony_tts(call_id, ai_response)
            
        else:
            logger.error(f"âŒ LLM call failed: status={response.status_code}")
            
    except Exception as e:
        logger.error(f"âŒ LLM processing failed: {e}")
        import traceback
        traceback.print_exc()

def generate_telephony_tts(call_id: str, text: str):
    """Generate streaming TTS audio for telephony output"""
    try:
        logger.info(f'ğŸµ Generating telephony TTS: "{text}" (call: {call_id})')
        tts_start = time.time()
        
        # TTS parameters for telephony
        tts_params = {
            "model": "qwen-tts-latest",
            "text": text,
            "voice": voice_settings.get('voice', 'Cherry'),
            "stream": True,
            "format": "pcm",
            "sample_rate": 24000  # Will be downsampled to 8kHz for CCC
        }
        
        # Apply voice control parameters
        for param in ['speed', 'pitch', 'volume', 'tone', 'emotion']:
            if param in voice_settings and voice_settings[param] != 'neutral':
                tts_params[param] = voice_settings[param]
        
        logger.info(f'ğŸµ TTS parameters: {tts_params}')
        
        # Generate streaming TTS
        responses = tts_client.call(**tts_params)
        
        if responses is None:
            raise ValueError("TTS API returned None response")
        
        # Process streaming PCM chunks
        chunk_count = 0
        first_chunk_latency = None
        
        for response in responses:
            if response and "output" in response and "audio" in response["output"] and "data" in response["output"]["audio"]:
                audio_string = response["output"]["audio"]["data"]
                pcm_bytes = base64.b64decode(audio_string)
                
                if pcm_bytes:
                    if first_chunk_latency is None:
                        first_chunk_latency = (time.time() - tts_start) * 1000
                        logger.info(f'ğŸµ First PCM chunk latency: {first_chunk_latency:.1f}ms')
                    
                    # Convert 24kHz PCM to 8kHz G.711 for CCC output
                    g711_audio = pcm_24khz_to_g711_8khz(pcm_bytes)
                    
                    # Send to CCC (placeholder - need actual CCC audio output)
                    send_audio_to_ccc(call_id, g711_audio)
                    
                    chunk_count += 1
                    logger.debug(f'ğŸ“¤ Telephony TTS chunk {chunk_count}: {len(pcm_bytes)} PCM â†’ {len(g711_audio)} G.711')
            elif response.status_code != 200:
                logger.error(f"âŒ TTS streaming error: {response.status_code}")
                break
        
        total_time = (time.time() - tts_start) * 1000
        effective_latency = first_chunk_latency if first_chunk_latency else 2000
        
        logger.info(f'âœ… Telephony TTS completed: {chunk_count} chunks, first chunk: {effective_latency:.1f}ms, total: {total_time:.1f}ms')
        
    except Exception as e:
        logger.error(f'âŒ Telephony TTS generation failed: {e}')
        import traceback
        traceback.print_exc()

def send_audio_to_ccc(call_id: str, g711_audio: bytes):
    """Send G.711 audio to CCC for customer playback"""
    try:
        # TODO: Implement actual CCC audio output
        # This would use CCC SDK to send audio back to the customer
        logger.debug(f'ğŸ“ Sending {len(g711_audio)} bytes G.711 audio to CCC call: {call_id}')
        
        # Placeholder for CCC audio output API call
        # Real implementation would use CCC client to send audio to call
        
    except Exception as e:
        logger.error(f'âŒ CCC audio output failed: {e}')

def handle_inbound_call(call_event: Dict) -> Dict:
    """Handle CCC inbound call event - Main entry point"""
    try:
        call_id = call_event.get('call_id')
        customer_phone = call_event.get('customer_phone', 'unknown')
        
        logger.info(f'ğŸ“ Handling inbound call: {call_id} from {customer_phone}')
        
        # Initialize session in memory
        conversation_sessions[call_id] = {
            'history': [],
            'customer_context': {
                'name': 'å®¢æˆ·',  # Could extract from CRM based on phone number
                'balance': 15000,
                'daysOverdue': 30,
                'previousContacts': 2,
                'riskLevel': 'ä¸­ç­‰'
            },
            'start_time': time.time(),
            'asr_processor': None
        }
        
        # Initialize ASR processor for this call
        asr_processor = TelephonyASRProcessor(call_id)
        if asr_processor.start_telephony_asr():
            conversation_sessions[call_id]['asr_processor'] = asr_processor
            logger.info(f'âœ… ASR processor started for call: {call_id}')
        else:
            logger.error(f'âŒ Failed to start ASR for call: {call_id}')
            return {'status': 'error', 'message': 'ASR initialization failed'}
        
        # Play greeting immediately upon connection
        play_inbound_greeting(call_id)
        
        return {
            'status': 'success', 
            'message': f'Inbound call {call_id} handled successfully',
            'call_id': call_id
        }
        
    except Exception as e:
        logger.error(f'âŒ Inbound call handling failed: {e}')
        return {'status': 'error', 'message': str(e)}

def play_inbound_greeting(call_id: str):
    """Play greeting upon inbound call connection - Adapted from continueGreetingSequence"""
    try:
        session = conversation_sessions.get(call_id, {})
        customer_context = session.get('customer_context', {})
        
        # Construct complete greeting message
        customer_name = customer_context.get('name', 'å®¢æˆ·')
        balance = customer_context.get('balance', 15000)
        days_overdue = customer_context.get('daysOverdue', 30)
        
        def format_chinese_amount(amount: int) -> str:
            if amount >= 10000:
                wan = amount // 10000
                remainder = amount % 10000
                if remainder == 0:
                    return f"{wan}ä¸‡å…ƒ"
                else:
                    return f"{wan}ä¸‡{remainder}å…ƒ"
            return f"{amount}å…ƒ"
        
        full_greeting = ''.join([
            f"{customer_name}æ‚¨å¥½ï¼Œæˆ‘æ˜¯å¹³å®‰é“¶è¡Œå‚¬æ”¶ä¸“å‘˜ï¼Œå·¥å·888888ã€‚",
            f"æ ¹æ®æˆ‘è¡Œè®°å½•ï¼Œæ‚¨æœ‰ä¸€ç¬”{format_chinese_amount(balance)}çš„é€¾æœŸæœ¬é‡‘ï¼Œé€¾æœŸäº†{days_overdue}å¤©ï¼Œå·²ä¸ŠæŠ¥å¾ä¿¡ç³»ç»Ÿã€‚",
            f"è¯·é—®æ‚¨ç°åœ¨æ–¹ä¾¿è°ˆè®ºè¿˜æ¬¾å®‰æ’å—ï¼Ÿ"
        ])
        
        logger.info(f'ğŸ¯ Playing inbound greeting: "{full_greeting}"')
        
        # Update conversation history
        session['history'].append({
            'sender': 'agent',
            'text': full_greeting,
            'timestamp': time.time()
        })
        conversation_sessions[call_id] = session
        
        # Generate and play greeting TTS
        generate_telephony_tts(call_id, full_greeting)
        
    except Exception as e:
        logger.error(f'âŒ Inbound greeting failed: {e}')

def handle_customer_speech(call_id: str, speech_text: str):
    """Handle recognized customer speech - Adapted from sendRecognizedTextToAI"""
    try:
        logger.info(f'ğŸ—£ï¸ Customer speech recognized: "{speech_text}" (call: {call_id})')
        
        if not speech_text.strip():
            logger.info('Empty speech text, skipping processing')
            return
        
        # Mark customer response in session
        session = conversation_sessions.get(call_id, {})
        session['customer_responded'] = True
        conversation_sessions[call_id] = session
        
        # Process through LLM and generate response
        process_telephony_llm_and_tts(call_id, speech_text)
        
    except Exception as e:
        logger.error(f'âŒ Customer speech handling failed: {e}')

def handle_call_end(call_id: str):
    """Clean up call session when call ends"""
    try:
        logger.info(f'ğŸ“ Ending call: {call_id}')
        
        # Stop ASR processor
        session = conversation_sessions.get(call_id, {})
        asr_processor = session.get('asr_processor')
        if asr_processor:
            asr_processor.stop_telephony_asr()
        
        # Clean up session (but keep for debugging if needed)
        if call_id in conversation_sessions:
            logger.info(f'ğŸ—‚ï¸ Call session ended: {len(session.get("history", []))} conversation turns')
            # Keep session for now - in production might save to external storage
            # del conversation_sessions[call_id]
        
    except Exception as e:
        logger.error(f'âŒ Call cleanup failed: {e}')

# Function Compute entry point
def handler(event, context):
    """Function Compute main handler - Entry point for CCC events"""
    try:
        logger.info(f'ğŸ“¡ Function Compute handler called: {event}')
        logger.debug(f'ğŸ“¡ Function Compute context: {context}')  # Log context for debugging
        
        # Initialize persistent connections if not already done
        if not asr_session and not llm_client:
            initialize_persistent_connections()
        
        # Parse CCC event
        event_type = event.get('event_type')
        call_data = event.get('call_data', {})
        
        if event_type == 'inbound_call':
            return handle_inbound_call(call_data)
        elif event_type == 'audio_data':
            # Handle incoming audio from customer
            call_id = call_data.get('call_id')
            audio_data = call_data.get('audio_data')  # G.711 encoded
            
            session = conversation_sessions.get(call_id, {})
            asr_processor = session.get('asr_processor')
            if asr_processor:
                asr_processor.send_audio_data(base64.b64decode(audio_data))
            
            return {'status': 'success', 'message': 'Audio processed'}
        elif event_type == 'call_end':
            call_id = call_data.get('call_id')
            handle_call_end(call_id)
            return {'status': 'success', 'message': 'Call ended'}
        else:
            logger.warning(f'Unknown event type: {event_type}')
            return {'status': 'error', 'message': f'Unknown event type: {event_type}'}
        
    except Exception as e:
        logger.error(f'âŒ Function Compute handler failed: {e}')
        import traceback
        traceback.print_exc()
        return {'status': 'error', 'message': str(e)}

# Development/testing entry point
if __name__ == '__main__':
    logger.info("ğŸš€ CCC Consolidated Server - Development Mode")
    logger.info("ğŸ¯ Features: Inbound calls, G.711â†”PCM conversion, Persistent connections")
    logger.info("ğŸ“ Architecture: No concurrency, In-memory sessions, Auto-greeting")
    
    # Initialize persistent connections
    initialize_persistent_connections()
    
    # Test with sample call event
    test_event = {
        'event_type': 'inbound_call',
        'call_data': {
            'call_id': 'test_call_001',
            'customer_phone': '+86138xxxxxxxx'
        }
    }
    
    test_context = {}  # Mock context for local testing
    
    logger.info('ğŸ§ª Testing with sample inbound call...')
    result = handler(test_event, test_context)
    logger.info(f'âœ… Test result: {result}')