"""
Core ChatbotService for CCC Digital Employee Integration
Implements DashScope streaming and professional collection logic
"""

import json
# import time  # âœ… REMOVED: No longer needed after removing artificial delays
import logging
from typing import Dict, Optional, Iterator, List, Any
from datetime import datetime, timedelta

# DashScope imports
import dashscope
from dashscope import Generation


DASHSCOPE_API_KEY = 'sk-89daa2f5ce954abba7770a87fa342db5'

# Local imports
from dtos import (
    BeginSessionRequest, DialogueRequest, AbortDialogueRequest, EndSessionRequest,
    AnswerDto, CustomerProfile, ConversationContext
)
from control_params import ControlParams, CollectionControlParams, IntentControlMapping

logger = logging.getLogger(__name__)

class IntentRecognizer:
    """Intent recognition for call control and collection scenarios"""
    
    COLLECTION_INTENTS = {
        # Transfer to human
        "è½¬äººå·¥": "TRANSFER_AGENT",
        "äººå·¥æœåŠ¡": "TRANSFER_AGENT",
        "ä¸“ä¸šå’¨è¯¢": "TRANSFER_AGENT",
        "è¦æ‰¾äºº": "TRANSFER_AGENT",
        
        # Payment related
        "åˆ†æœŸè¿˜æ¬¾": "PAYMENT_PLAN",
        "è¿˜æ¬¾è®¡åˆ’": "PAYMENT_PLAN", 
        "åˆ†æœŸä»˜æ¬¾": "PAYMENT_PLAN",
        "æ€ä¹ˆè¿˜": "PAYMENT_PLAN",
        
        # Scheduling
        "ç¨åè”ç³»": "SCHEDULE_CALLBACK",
        "æ™šç‚¹æ‰“": "SCHEDULE_CALLBACK",
        "æ”¹å¤©è”ç³»": "SCHEDULE_CALLBACK",
        "ç°åœ¨ä¸æ–¹ä¾¿": "SCHEDULE_CALLBACK",
        
        # Resistance/Negotiation
        "æ²¡æœ‰é’±": "NO_MONEY",
        "è¿˜ä¸èµ·": "NO_MONEY",
        "æš‚æ—¶å›°éš¾": "NO_MONEY",
        
        # Termination
        "æŒ‚æœº": "HANGUP",
        "ç»“æŸé€šè¯": "HANGUP",
        "ä¸æƒ³èŠ": "HANGUP"
    }
    
    @classmethod
    def detect_intent(cls, customer_input: str) -> Optional[str]:
        """Detect customer intent from input text"""
        customer_input = customer_input.strip().lower()
        
        for keyword, intent in cls.COLLECTION_INTENTS.items():
            if keyword in customer_input:
                logger.info(f"ğŸ¯ Intent detected: {intent} (keyword: {keyword})")
                return intent
        
        return None

class ChatbotService:
    """Core chatbot service with DashScope integration"""
    
    def __init__(self):
        self.active_sessions: Dict[str, ConversationContext] = {}
        self.generation_client = Generation()
        
        # Professional collection prompt template
        self.COLLECTION_PROMPT = """ä½ æ˜¯ä¸“ä¸šçš„é“¶è¡Œå‚¬æ”¶ä¸“å‘˜ï¼Œæ­£åœ¨è¿›è¡Œå€ºåŠ¡å‚¬æ”¶å¯¹è¯ã€‚

å®¢æˆ·ä¿¡æ¯ï¼š
- å§“åï¼š{customer_name}
- é€¾æœŸé‡‘é¢ï¼š{overdue_amount}
- é€¾æœŸå¤©æ•°ï¼š{overdue_days}å¤©
- è”ç³»å†å²ï¼š{contact_history}

å¯¹è¯å†å²ï¼š
{conversation_history}

å¯¹è¯è¦æ±‚ï¼š
1. è¯­æ°”ä¸“ä¸šã€ç¤¼è²Œä½†åšå®š
2. ä½¿ç”¨é“¶è¡Œæœ¯è¯­ï¼šé€¾æœŸæœ¬é‡‘ã€è¿˜æ¬¾ä¹‰åŠ¡ã€å¾ä¿¡è®°å½•
3. æä¾›å…·ä½“è§£å†³æ–¹æ¡ˆï¼ˆåˆ†æœŸè¿˜æ¬¾ã€ä¸€æ¬¡æ€§ä¼˜æƒ ç­‰ï¼‰
4. å¼ºè°ƒé€¾æœŸå¯¹ä¸ªäººå¾ä¿¡çš„å½±å“
5. å›å¤ç®€æ´æ˜äº†ï¼Œé€‚åˆè¯­éŸ³æ’­æŠ¥ï¼ˆ30å­—ä»¥å†…ï¼‰
6. ä¿æŒåˆè§„ï¼Œé¿å…è¿‡åº¦æ–½å‹

å®¢æˆ·è¯´ï¼š"{customer_input}"

è¯·å›å¤ï¼š"""
        
        logger.info("âœ… ChatbotService initialized with DashScope integration")
    
    def get_or_create_session(self, session_id: str) -> ConversationContext:
        """Get or create conversation session"""
        if session_id not in self.active_sessions:
            self.active_sessions[session_id] = ConversationContext(session_id)
            logger.info(f"ğŸ“ Created new session: {session_id}")
        
        return self.active_sessions[session_id]
    
    def format_chinese_amount(self, amount_str: str) -> str:
        """Format amount for Chinese TTS"""
        try:
            amount = float(amount_str.replace('å…ƒ', '').replace(',', ''))
            if amount >= 10000:
                return f"{amount/10000:.1f}ä¸‡å…ƒ".replace('.0', '')
            else:
                return f"{amount:.0f}å…ƒ"
        except:
            return amount_str
    
    def build_collection_context(self, request: DialogueRequest, context: ConversationContext) -> str:
        """Build professional collection conversation context"""
        # Create customer profile if not exists
        if context.customer_profile is None:
            profile_data = {
                'name': request.customer_name,
                'overdue_amount': getattr(request, 'call_context', {}).get('overdueAmount', '15000å…ƒ'),
                'overdue_days': getattr(request, 'call_context', {}).get('overdueDays', '30'),
                'contact_history': 'é¦–æ¬¡è”ç³»'
            }
            context.customer_profile = CustomerProfile(profile_data)
        
        profile = context.customer_profile
        
        return self.COLLECTION_PROMPT.format(
            customer_name=profile.name,
            overdue_amount=profile.format_amount_chinese(),
            overdue_days=profile.overdue_days,
            contact_history=profile.contact_history,
            conversation_history='\n'.join(context.dialogue_history[-6:]),  # Last 3 turns
            customer_input=request.text
        )
    
    def stream_qwen_response(self, prompt: str, request: DialogueRequest) -> Iterator[str]:
        """Stream DashScope Qwen LLM response with CCC-compatible format"""
        try:
            messages = [{'role': 'user', 'content': prompt}]
            
            # âœ… FIXED: Align API parameters with Java implementation
            # Java uses: .model("qwen-plus"), .incrementalOutput(false), .resultFormat(TEXT)
            responses = Generation.call(
                api_key=DASHSCOPE_API_KEY,
                model='qwen-plus',  # Same as Java
                messages=messages,
                stream=True,  # Python equivalent of Java's streaming
                result_format='text',  # Align with Java's ResultFormat.TEXT
                temperature=0.7,  # Aligned with Java (Java uses default)
                max_tokens=200,  # âœ… FIXED: Increased from 80 to prevent premature cutoff
                top_p=0.8,  # Fine for streaming
                incremental_output=True  # âœ… Better for streaming than Java's false
            )
            
            full_response = ""
            previous_length = 0
            chunk_count = 0
            
            for response in responses:
                if response.status_code == 200:
                    if response.output and hasattr(response.output, 'text'):
                        current_text = response.output.text
                        
                        # âœ… FIXED: Check finish_reason for automatic stream termination (align with Java)
                        finish_reason = getattr(response.output, 'finish_reason', None)
                        is_stream_end = (finish_reason == 'stop' or finish_reason == 'length')
                        
                        if current_text and len(current_text) > previous_length:
                            # Extract only the new delta (incremental text)
                            delta_text = current_text[previous_length:]
                            full_response = current_text
                            previous_length = len(current_text)
                            chunk_count += 1
                            
                            # âœ… FIXED: Use finish_reason for stream_end like Java (.streamEnd("stop".equals(...)))
                            answer = AnswerDto(
                                answer_text=delta_text,  # Send only the delta, not full text
                                stream_end=is_stream_end,  # âœ… Based on finish_reason, not manual
                                session_id=request.session_id,
                                stream_id=request.stream_id,
                                control_params_list=ControlParams.voice_control(interruptible=True)
                            )
                            
                            yield answer.to_sse_format(request.request_id)
                            
                            # Log completion when stream ends naturally
                            if is_stream_end:
                                logger.info(f"ğŸ Stream completed naturally (finish_reason: {finish_reason})")
                                break
                            
                            # âœ… FIXED: Remove artificial delay - let natural streaming timing handle this
                            # time.sleep(0.05)  # Removed to prevent timing issues
                        elif is_stream_end and full_response.strip():
                            # Handle case where stream ends without new text
                            final_answer = AnswerDto(
                                answer_text="",
                                stream_end=True,
                                session_id=request.session_id,
                                stream_id=request.stream_id,
                                control_params_list=ControlParams.voice_control(interruptible=True)
                            )
                            yield final_answer.to_sse_format(request.request_id)
                            logger.info(f"ğŸ Stream completed without new text (finish_reason: {finish_reason})")
                            break
                else:
                    logger.error(f"âŒ DashScope error: {response}")
                    break
            
            # âœ… FIXED: Remove empty final response - let stream end naturally based on finish_reason
            # Stream completion is handled by the last chunk with proper finish_reason detection
            if full_response.strip():
                logger.info(f"ğŸ¤– LLM Response ({chunk_count} chunks): {full_response.strip()}")
            else:
                # Fallback response
                fallback_answer = AnswerDto(
                    answer_text="å¾ˆæŠ±æ­‰ï¼Œè¯·æ‚¨é‡å¤ä¸€ä¸‹åˆšæ‰çš„é—®é¢˜ã€‚",
                    stream_end=True,
                    session_id=request.session_id,
                    stream_id=request.stream_id,
                    control_params_list=ControlParams.voice_control(interruptible=True)
                )
                yield fallback_answer.to_sse_format(request.request_id)
                
        except Exception as e:
            logger.error(f"âŒ Streaming LLM error: {e}")
            error_answer = AnswerDto(
                answer_text="ç³»ç»Ÿæš‚æ—¶æ— æ³•å¤„ç†ï¼Œè¯·ç¨åå†è¯•ã€‚",
                stream_end=True,
                session_id=request.session_id,
                stream_id=request.stream_id,
                control_params_list=ControlParams.voice_control(interruptible=True)
            )
            yield error_answer.to_sse_format(request.request_id)
    
    def begin_session(self, request: BeginSessionRequest) -> Iterator[str]:
        """Begin conversation session with professional greeting"""
        try:
            # Create or get session
            context = self.get_or_create_session(request.session_id)
            
            # Create customer profile
            profile_data = {
                'name': request.customer_name,
                'overdue_amount': request.overdue_amount,
                'overdue_days': request.overdue_days,
                'contact_history': request.contact_history
            }
            context.customer_profile = CustomerProfile(profile_data)
            
            # Generate professional greeting
            formatted_amount = self.format_chinese_amount(request.overdue_amount)
            greeting = f"æ‚¨å¥½{request.customer_name}ï¼Œæˆ‘æ˜¯é“¶è¡Œå‚¬æ”¶ä¸“å‘˜ã€‚å…³äºæ‚¨{formatted_amount}é€¾æœŸ{request.overdue_days}å¤©çš„æ¬¾é¡¹ï¼Œéœ€è¦å’Œæ‚¨åå•†è¿˜æ¬¾äº‹å®œã€‚"
            
            # Create answer with voice control - match CCC expectations
            answer = AnswerDto(
                answer_text=greeting,
                stream_end=True,  # End the greeting stream, but conversation continues
                session_id=request.session_id,     # CRITICAL: Include session ID
                stream_id=request.stream_id,       # CRITICAL: Include stream ID
                control_params_list=ControlParams.voice_control(
                    interruptible=False,  # Don't allow interruption during greeting
                    silence_timeout=5000  # 5s timeout to match CCC behavior
                )
            )
            
            yield answer.to_sse_format(request.request_id)  # CRITICAL: Pass request ID
            
            logger.info(f"ğŸ‘‹ Welcome message: {request.session_id} - {greeting}")
            
        except Exception as e:
            logger.error(f"âŒ Begin session error: {e}")
            error_answer = AnswerDto(
                answer_text="ç³»ç»Ÿåˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨ç­‰ç‰‡åˆ»ã€‚",
                stream_end=True,
                session_id=request.session_id,
                stream_id=request.stream_id,
                control_params_list=ControlParams.voice_control(interruptible=True)
            )
            yield error_answer.to_sse_format(request.request_id)
    
    def dialogue(self, request: DialogueRequest) -> Iterator[str]:
        """Process customer dialogue with intent detection and streaming response"""
        try:
            # Get session context
            context = self.get_or_create_session(request.session_id)
            
            # Detect customer intent
            intent = IntentRecognizer.detect_intent(request.text)
            context.last_intent = intent
            
            # Handle specific intents with control parameters
            if intent:
                control_params = IntentControlMapping.get_control_params(intent)
                
                # Generate intent-specific response
                if intent == "TRANSFER_AGENT":
                    response_text = "å¥½çš„ï¼Œæˆ‘å¸®æ‚¨è½¬æ¥ä¸“ä¸šçš„åå•†ä¸“å‘˜ï¼Œè¯·ç¨ç­‰ã€‚"
                elif intent == "PAYMENT_PLAN":
                    response_text = "æˆ‘æ¥ä¸ºæ‚¨ä»‹ç»åˆ†æœŸè¿˜æ¬¾æ–¹æ¡ˆã€‚"
                elif intent == "SCHEDULE_CALLBACK":
                    response_text = "å¥½çš„ï¼Œæˆ‘ä»¬å®‰æ’åˆé€‚çš„æ—¶é—´å†æ¬¡è”ç³»æ‚¨ã€‚"
                elif intent == "NO_MONEY":
                    response_text = "ç†è§£æ‚¨çš„å›°éš¾ï¼Œæˆ‘ä»¬å¯ä»¥åå•†åˆé€‚çš„è¿˜æ¬¾æ–¹æ¡ˆã€‚"
                elif intent == "HANGUP":
                    response_text = "æ„Ÿè°¢æ‚¨çš„é…åˆï¼Œç¥æ‚¨ç”Ÿæ´»æ„‰å¿«ã€‚"
                    context.control_state = "terminated"
                else:
                    # Use LLM for complex responses
                    prompt = self.build_collection_context(request, context)
                    for chunk in self.stream_qwen_response(prompt, request):
                        yield chunk
                    return
                
                # Create answer with intent-based control
                answer = AnswerDto(
                    answer_text=response_text,
                    stream_end=True,
                    session_id=request.session_id,
                    stream_id=request.stream_id,
                    control_params_list=control_params
                )
                
                yield answer.to_sse_format(request.request_id)
                
                # Update conversation history
                context.add_dialogue_turn(request.text, response_text)
                
            else:
                # No specific intent - use LLM for natural conversation
                prompt = self.build_collection_context(request, context)
                
                # âœ… FIXED: Simplify response tracking - pass response directly from stream_qwen_response
                full_ai_response = ""
                for chunk in self.stream_qwen_response(prompt, request):
                    yield chunk
                    # Extract the actual response text for history (simplified)
                    try:
                        chunk_json = json.loads(chunk)
                        chunk_text = chunk_json.get('data', {}).get('answer', '')
                        if chunk_text and not chunk_json.get('data', {}).get('streamEnd', False):
                            full_ai_response += chunk_text
                    except:
                        pass
                
                # âœ… FIXED: Simplified conversation history update
                if full_ai_response.strip():
                    context.add_dialogue_turn(request.text, full_ai_response.strip())
            
        except Exception as e:
            logger.error(f"âŒ Dialogue error: {e}")
            error_answer = AnswerDto(
                answer_text="å¾ˆæŠ±æ­‰ï¼Œè¯·æ‚¨é‡å¤ä¸€ä¸‹é—®é¢˜ã€‚",
                stream_end=True,
                session_id=request.session_id,
                stream_id=request.stream_id,
                control_params_list=ControlParams.voice_control(interruptible=True)
            )
            yield error_answer.to_sse_format(request.request_id)
    
    def abort_dialogue(self, request: AbortDialogueRequest) -> Dict[str, Any]:
        """Abort current dialogue turn"""
        try:
            context = self.get_or_create_session(request.session_id)
            context.control_state = "aborted"
            
            logger.info(f"ğŸš« Dialogue aborted: {request.session_id} - {request.reason}")
            
            return {
                "sessionId": request.session_id,
                "status": "aborted",
                "reason": request.reason,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"âŒ Abort dialogue error: {e}")
            raise
    
    def end_session(self, request: EndSessionRequest) -> Dict[str, Any]:
        """End conversation session with summary"""
        try:
            if request.session_id in self.active_sessions:
                context = self.active_sessions[request.session_id]
                context.control_state = "ended"
                
                # Generate session summary
                summary = context.get_conversation_summary()
                
                logger.info(f"ğŸ Session ended: {request.session_id}")
                logger.info(f"   ğŸ“Š Duration: {summary['duration']}")
                logger.info(f"   ğŸ“Š Turns: {summary['turns']}")
                logger.info(f"   ğŸ“Š Last intent: {summary['last_intent']}")
                
                # Keep session for analytics (in production, move to persistent storage)
                # del self.active_sessions[request.session_id]
                
                return {
                    "sessionId": request.session_id,
                    "status": "ended",
                    "summary": summary,
                    "endReason": request.end_reason,
                    "timestamp": datetime.now().isoformat()
                }
            else:
                return {
                    "sessionId": request.session_id,
                    "status": "not_found",
                    "timestamp": datetime.now().isoformat()
                }
                
        except Exception as e:
            logger.error(f"âŒ End session error: {e}")
            raise