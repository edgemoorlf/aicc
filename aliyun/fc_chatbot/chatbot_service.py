"""
Core ChatbotService for CCC Digital Employee Integration
Implements DashScope streaming and professional collection logic
"""

import json
import time
import logging
from typing import Dict, Optional, Iterator, List, Any
from datetime import datetime, timedelta

# DashScope imports
import dashscope
from dashscope import Generation


DASHSCOPE_API_KEY = 'sk-89daa2f5ce954abba7770a87fa342db5'

# Local imports
from dtos import (
    BeginSessionRequest, DialogueRequest, AbortDialogueRequest, EndSessionRequest,
    AnswerDto, CustomerProfile, ConversationContext
)
from control_params import ControlParams, CollectionControlParams, IntentControlMapping

logger = logging.getLogger(__name__)

class IntentRecognizer:
    """Intent recognition for call control and collection scenarios"""
    
    COLLECTION_INTENTS = {
        # Transfer to human
        "è½¬äººå·¥": "TRANSFER_AGENT",
        "äººå·¥æœåŠ¡": "TRANSFER_AGENT",
        "ä¸“ä¸šå’¨è¯¢": "TRANSFER_AGENT",
        "è¦æ‰¾äºº": "TRANSFER_AGENT",
        
        # Payment related
        "åˆ†æœŸè¿˜æ¬¾": "PAYMENT_PLAN",
        "è¿˜æ¬¾è®¡åˆ’": "PAYMENT_PLAN", 
        "åˆ†æœŸä»˜æ¬¾": "PAYMENT_PLAN",
        "æ€ä¹ˆè¿˜": "PAYMENT_PLAN",
        
        # Scheduling
        "ç¨åè”ç³»": "SCHEDULE_CALLBACK",
        "æ™šç‚¹æ‰“": "SCHEDULE_CALLBACK",
        "æ”¹å¤©è”ç³»": "SCHEDULE_CALLBACK",
        "ç°åœ¨ä¸æ–¹ä¾¿": "SCHEDULE_CALLBACK",
        
        # Resistance/Negotiation
        "æ²¡æœ‰é’±": "NO_MONEY",
        "è¿˜ä¸èµ·": "NO_MONEY",
        "æš‚æ—¶å›°éš¾": "NO_MONEY",
        
        # Termination
        "æŒ‚æœº": "HANGUP",
        "ç»“æŸé€šè¯": "HANGUP",
        "ä¸æƒ³èŠ": "HANGUP"
    }
    
    @classmethod
    def detect_intent(cls, customer_input: str) -> Optional[str]:
        """Detect customer intent from input text"""
        customer_input = customer_input.strip().lower()
        
        for keyword, intent in cls.COLLECTION_INTENTS.items():
            if keyword in customer_input:
                logger.info(f"ğŸ¯ Intent detected: {intent} (keyword: {keyword})")
                return intent
        
        return None

class ChatbotService:
    """Core chatbot service with DashScope integration"""
    
    def __init__(self):
        self.active_sessions: Dict[str, ConversationContext] = {}
        self.generation_client = Generation()
        
        # Professional collection prompt template
        self.COLLECTION_PROMPT = """ä½ æ˜¯ä¸“ä¸šçš„é“¶è¡Œå‚¬æ”¶ä¸“å‘˜ï¼Œæ­£åœ¨è¿›è¡Œå€ºåŠ¡å‚¬æ”¶å¯¹è¯ã€‚

å®¢æˆ·ä¿¡æ¯ï¼š
- å§“åï¼š{customer_name}
- é€¾æœŸé‡‘é¢ï¼š{overdue_amount}
- é€¾æœŸå¤©æ•°ï¼š{overdue_days}å¤©
- è”ç³»å†å²ï¼š{contact_history}

å¯¹è¯å†å²ï¼š
{conversation_history}

å¯¹è¯è¦æ±‚ï¼š
1. è¯­æ°”ä¸“ä¸šã€ç¤¼è²Œä½†åšå®š
2. ä½¿ç”¨é“¶è¡Œæœ¯è¯­ï¼šé€¾æœŸæœ¬é‡‘ã€è¿˜æ¬¾ä¹‰åŠ¡ã€å¾ä¿¡è®°å½•
3. æä¾›å…·ä½“è§£å†³æ–¹æ¡ˆï¼ˆåˆ†æœŸè¿˜æ¬¾ã€ä¸€æ¬¡æ€§ä¼˜æƒ ç­‰ï¼‰
4. å¼ºè°ƒé€¾æœŸå¯¹ä¸ªäººå¾ä¿¡çš„å½±å“
5. å›å¤ç®€æ´æ˜äº†ï¼Œé€‚åˆè¯­éŸ³æ’­æŠ¥ï¼ˆ30å­—ä»¥å†…ï¼‰
6. ä¿æŒåˆè§„ï¼Œé¿å…è¿‡åº¦æ–½å‹

å®¢æˆ·è¯´ï¼š"{customer_input}"

è¯·å›å¤ï¼š"""
        
        logger.info("âœ… ChatbotService initialized with DashScope integration")
    
    def get_or_create_session(self, session_id: str) -> ConversationContext:
        """Get or create conversation session"""
        if session_id not in self.active_sessions:
            self.active_sessions[session_id] = ConversationContext(session_id)
            logger.info(f"ğŸ“ Created new session: {session_id}")
        
        return self.active_sessions[session_id]
    
    def format_chinese_amount(self, amount_str: str) -> str:
        """Format amount for Chinese TTS"""
        try:
            amount = float(amount_str.replace('å…ƒ', '').replace(',', ''))
            if amount >= 10000:
                return f"{amount/10000:.1f}ä¸‡å…ƒ".replace('.0', '')
            else:
                return f"{amount:.0f}å…ƒ"
        except:
            return amount_str
    
    def build_collection_context(self, request: DialogueRequest, context: ConversationContext) -> str:
        """Build professional collection conversation context"""
        # Create customer profile if not exists
        if context.customer_profile is None:
            profile_data = {
                'name': request.customer_name,
                'overdue_amount': getattr(request, 'call_context', {}).get('overdueAmount', '15000å…ƒ'),
                'overdue_days': getattr(request, 'call_context', {}).get('overdueDays', '30'),
                'contact_history': 'é¦–æ¬¡è”ç³»'
            }
            context.customer_profile = CustomerProfile(profile_data)
        
        profile = context.customer_profile
        
        return self.COLLECTION_PROMPT.format(
            customer_name=profile.name,
            overdue_amount=profile.format_amount_chinese(),
            overdue_days=profile.overdue_days,
            contact_history=profile.contact_history,
            conversation_history='\n'.join(context.dialogue_history[-6:]),  # Last 3 turns
            customer_input=request.text
        )
    
    def stream_qwen_response(self, prompt: str, request: DialogueRequest) -> Iterator[str]:
        """Stream DashScope Qwen LLM response with CCC-compatible format"""
        try:
            messages = [{'role': 'user', 'content': prompt}]
            
            # Call DashScope streaming API
            responses = Generation.call(
                api_key=DASHSCOPE_API_KEY,
                model='qwen-plus',
                messages=messages,
                stream=True,
                temperature=0.7,
                max_tokens=80,  # Keep responses concise for TTS
                top_p=0.8
            )
            
            full_response = ""
            previous_length = 0
            chunk_count = 0
            
            for response in responses:
                if response.status_code == 200:
                    if response.output and hasattr(response.output, 'text'):
                        current_text = response.output.text
                        if current_text and len(current_text) > previous_length:
                            # Extract only the new delta (incremental text)
                            delta_text = current_text[previous_length:]
                            full_response = current_text
                            previous_length = len(current_text)
                            chunk_count += 1
                            
                            # Create answer DTO with incremental text for streaming
                            answer = AnswerDto(
                                answer_text=delta_text,  # Send only the delta, not full text
                                stream_end=False,
                                session_id=request.session_id,
                                stream_id=request.stream_id,
                                control_params_list=ControlParams.voice_control(interruptible=True)
                            )
                            
                            yield answer.to_sse_format(request.request_id)
                            
                            # Small delay between chunks for natural streaming
                            time.sleep(0.05)
                else:
                    logger.error(f"âŒ DashScope error: {response}")
                    break
            
            # Final response with stream end flag (empty text, just end signal)
            if full_response.strip():
                final_answer = AnswerDto(
                    answer_text="",  # Empty text for stream end signal
                    stream_end=True,
                    session_id=request.session_id,
                    stream_id=request.stream_id,
                    control_params_list=ControlParams.voice_control(interruptible=True)
                )
                yield final_answer.to_sse_format(request.request_id)
                
                logger.info(f"ğŸ¤– LLM Response ({chunk_count} chunks): {full_response.strip()}")
            else:
                # Fallback response
                fallback_answer = AnswerDto(
                    answer_text="å¾ˆæŠ±æ­‰ï¼Œè¯·æ‚¨é‡å¤ä¸€ä¸‹åˆšæ‰çš„é—®é¢˜ã€‚",
                    stream_end=True,
                    session_id=request.session_id,
                    stream_id=request.stream_id,
                    control_params_list=ControlParams.voice_control(interruptible=True)
                )
                yield fallback_answer.to_sse_format(request.request_id)
                
        except Exception as e:
            logger.error(f"âŒ Streaming LLM error: {e}")
            error_answer = AnswerDto(
                answer_text="ç³»ç»Ÿæš‚æ—¶æ— æ³•å¤„ç†ï¼Œè¯·ç¨åå†è¯•ã€‚",
                stream_end=True,
                session_id=request.session_id,
                stream_id=request.stream_id,
                control_params_list=ControlParams.voice_control(interruptible=True)
            )
            yield error_answer.to_sse_format(request.request_id)
    
    def begin_session(self, request: BeginSessionRequest) -> Iterator[str]:
        """Begin conversation session with professional greeting"""
        try:
            # Create or get session
            context = self.get_or_create_session(request.session_id)
            
            # Create customer profile
            profile_data = {
                'name': request.customer_name,
                'overdue_amount': request.overdue_amount,
                'overdue_days': request.overdue_days,
                'contact_history': request.contact_history
            }
            context.customer_profile = CustomerProfile(profile_data)
            
            # Generate professional greeting
            formatted_amount = self.format_chinese_amount(request.overdue_amount)
            greeting = f"æ‚¨å¥½{request.customer_name}ï¼Œæˆ‘æ˜¯é“¶è¡Œå‚¬æ”¶ä¸“å‘˜ã€‚å…³äºæ‚¨{formatted_amount}é€¾æœŸ{request.overdue_days}å¤©çš„æ¬¾é¡¹ï¼Œéœ€è¦å’Œæ‚¨åå•†è¿˜æ¬¾äº‹å®œã€‚"
            
            # Create answer with voice control - match CCC expectations
            answer = AnswerDto(
                answer_text=greeting,
                stream_end=True,  # End the greeting stream, but conversation continues
                session_id=request.session_id,     # CRITICAL: Include session ID
                stream_id=request.stream_id,       # CRITICAL: Include stream ID
                control_params_list=ControlParams.voice_control(
                    interruptible=False,  # Don't allow interruption during greeting
                    silence_timeout=5000  # 5s timeout to match CCC behavior
                )
            )
            
            yield answer.to_sse_format(request.request_id)  # CRITICAL: Pass request ID
            
            logger.info(f"ğŸ‘‹ Welcome message: {request.session_id} - {greeting}")
            
        except Exception as e:
            logger.error(f"âŒ Begin session error: {e}")
            error_answer = AnswerDto(
                answer_text="ç³»ç»Ÿåˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨ç­‰ç‰‡åˆ»ã€‚",
                stream_end=True,
                session_id=request.session_id,
                stream_id=request.stream_id,
                control_params_list=ControlParams.voice_control(interruptible=True)
            )
            yield error_answer.to_sse_format(request.request_id)
    
    def dialogue(self, request: DialogueRequest) -> Iterator[str]:
        """Process customer dialogue with intent detection and streaming response"""
        try:
            # Get session context
            context = self.get_or_create_session(request.session_id)
            
            # Detect customer intent
            intent = IntentRecognizer.detect_intent(request.text)
            context.last_intent = intent
            
            # Handle specific intents with control parameters
            if intent:
                control_params = IntentControlMapping.get_control_params(intent)
                
                # Generate intent-specific response
                if intent == "TRANSFER_AGENT":
                    response_text = "å¥½çš„ï¼Œæˆ‘å¸®æ‚¨è½¬æ¥ä¸“ä¸šçš„åå•†ä¸“å‘˜ï¼Œè¯·ç¨ç­‰ã€‚"
                elif intent == "PAYMENT_PLAN":
                    response_text = "æˆ‘æ¥ä¸ºæ‚¨ä»‹ç»åˆ†æœŸè¿˜æ¬¾æ–¹æ¡ˆã€‚"
                elif intent == "SCHEDULE_CALLBACK":
                    response_text = "å¥½çš„ï¼Œæˆ‘ä»¬å®‰æ’åˆé€‚çš„æ—¶é—´å†æ¬¡è”ç³»æ‚¨ã€‚"
                elif intent == "NO_MONEY":
                    response_text = "ç†è§£æ‚¨çš„å›°éš¾ï¼Œæˆ‘ä»¬å¯ä»¥åå•†åˆé€‚çš„è¿˜æ¬¾æ–¹æ¡ˆã€‚"
                elif intent == "HANGUP":
                    response_text = "æ„Ÿè°¢æ‚¨çš„é…åˆï¼Œç¥æ‚¨ç”Ÿæ´»æ„‰å¿«ã€‚"
                    context.control_state = "terminated"
                else:
                    # Use LLM for complex responses
                    prompt = self.build_collection_context(request, context)
                    for chunk in self.stream_qwen_response(prompt, request):
                        yield chunk
                    return
                
                # Create answer with intent-based control
                answer = AnswerDto(
                    answer_text=response_text,
                    stream_end=True,
                    session_id=request.session_id,
                    stream_id=request.stream_id,
                    control_params_list=control_params
                )
                
                yield answer.to_sse_format(request.request_id)
                
                # Update conversation history
                context.add_dialogue_turn(request.text, response_text)
                
            else:
                # No specific intent - use LLM for natural conversation
                prompt = self.build_collection_context(request, context)
                
                ai_response_chunks = []
                for chunk in self.stream_qwen_response(prompt, request):
                    ai_response_chunks.append(chunk)
                    yield chunk
                
                # Extract final response for history
                if ai_response_chunks:
                    try:
                        # Reconstruct full response from chunks
                        full_response = ""
                        for chunk_str in ai_response_chunks:
                            chunk_json = json.loads(chunk_str)
                            answer_text = chunk_json.get('data', {}).get('answer', '')
                            if answer_text and not chunk_json.get('data', {}).get('streamEnd', False):
                                full_response += answer_text
                        
                        if full_response:
                            context.add_dialogue_turn(request.text, full_response)
                    except:
                        pass
            
        except Exception as e:
            logger.error(f"âŒ Dialogue error: {e}")
            error_answer = AnswerDto(
                answer_text="å¾ˆæŠ±æ­‰ï¼Œè¯·æ‚¨é‡å¤ä¸€ä¸‹é—®é¢˜ã€‚",
                stream_end=True,
                session_id=request.session_id,
                stream_id=request.stream_id,
                control_params_list=ControlParams.voice_control(interruptible=True)
            )
            yield error_answer.to_sse_format(request.request_id)
    
    def abort_dialogue(self, request: AbortDialogueRequest) -> Dict[str, Any]:
        """Abort current dialogue turn"""
        try:
            context = self.get_or_create_session(request.session_id)
            context.control_state = "aborted"
            
            logger.info(f"ğŸš« Dialogue aborted: {request.session_id} - {request.reason}")
            
            return {
                "sessionId": request.session_id,
                "status": "aborted",
                "reason": request.reason,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"âŒ Abort dialogue error: {e}")
            raise
    
    def end_session(self, request: EndSessionRequest) -> Dict[str, Any]:
        """End conversation session with summary"""
        try:
            if request.session_id in self.active_sessions:
                context = self.active_sessions[request.session_id]
                context.control_state = "ended"
                
                # Generate session summary
                summary = context.get_conversation_summary()
                
                logger.info(f"ğŸ Session ended: {request.session_id}")
                logger.info(f"   ğŸ“Š Duration: {summary['duration']}")
                logger.info(f"   ğŸ“Š Turns: {summary['turns']}")
                logger.info(f"   ğŸ“Š Last intent: {summary['last_intent']}")
                
                # Keep session for analytics (in production, move to persistent storage)
                # del self.active_sessions[request.session_id]
                
                return {
                    "sessionId": request.session_id,
                    "status": "ended",
                    "summary": summary,
                    "endReason": request.end_reason,
                    "timestamp": datetime.now().isoformat()
                }
            else:
                return {
                    "sessionId": request.session_id,
                    "status": "not_found",
                    "timestamp": datetime.now().isoformat()
                }
                
        except Exception as e:
            logger.error(f"âŒ End session error: {e}")
            raise